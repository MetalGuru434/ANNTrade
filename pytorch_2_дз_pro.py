# -*- coding: utf-8 -*-
""""PyTorch #2.ДЗ PRO.ipynb"

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1RMLQpFHz9tcN6_EoqDLGwHCyErPtRI2e

# Задание Pro

Необходимо, на основании представленного датасета 'https://storage.yandexcloud.net/aiueducation/Content/base/l5/middle_fmr.zip', разработать свёрточную нейросеть на PyTorch.

Рекомендации по выполнению задания:

1. Создать общую выборку из тензоров;
2. Разделить общую выборку на: тренировочную, валидационную, тестовую;
3. Создать архитектуру свёрточной нейросети, применяя следуюшие слои: Linear, Conv2D, Max Pooling, Average Pooling, Dropout, Batch Normalization;
4. Обучить модель нейросети, применяя метрики: "Loss ("Потери", "Ошибка")" и "Accuracy ("Точность")";
5. Показать результат обучения модели на тестовой выборке.

# Подготовка
"""

# Подключение модуля для загрузки данных из облака
import gdown

# Загрузка zip-архива с датасетом из облака на диск виртуальной машины colab
gdown.download('https://storage.yandexcloud.net/aiueducation/Content/base/l5/middle_fmr.zip', None, quiet=True)

# Разархивация датасета в директорию 'content/cars'
!unzip -qo "middle_fmr.zip" -d cars/

# Папка с папками картинок, рассортированных по категориям
IMAGE_PATH = 'cars/'

# Для работы с файлами
import os

os.listdir(IMAGE_PATH)

# Определение списка имен классов
CLASS_LIST = sorted(os.listdir(IMAGE_PATH))

# Определение количества классов
CLASS_COUNT = len(CLASS_LIST)

# Проверка результата
print(f'Количество классов: {CLASS_COUNT}, метки классов: {CLASS_LIST}')

i = 1

# Формирование пути к выборке одной марки авто
f'{IMAGE_PATH}{CLASS_LIST[i]}/'

from time import sleep as sl

for cls in CLASS_LIST:
    print(cls, ':', os.listdir(f'{IMAGE_PATH}{cls}/'))
    sl(0.5)

from PIL import Image                     # Отрисовка изображений
import random                             # Генерация случайных чисел
import matplotlib.pyplot as plt           # Отрисовка графиков

# Создание заготовки для изображений всех классов
fig, axs = plt.subplots(1, CLASS_COUNT, figsize=(25, 5))

# Для всех номеров классов:
for i in range(CLASS_COUNT):
    # Формирование пути к папке содержимого класса
    car_path = f'{IMAGE_PATH}{CLASS_LIST[i]}/'
    # Выбор случайного фото из i-го класса
    img_path = car_path + random.choice(os.listdir(car_path))
    # Отображение фотографии (подробнее будет объяснено далее)
    axs[i].set_title(CLASS_LIST[i])
    axs[i].imshow(Image.open(img_path))
    axs[i].axis('off')

# Отрисовка всего полотна
plt.show()

"""## Создание списков файлов и их меток класса

"""

CLASS_COUNT

data_files = []                           # Cписок путей к файлам картинок
data_labels = []                          # Список меток классов, соответствующих файлам

for class_label in range(CLASS_COUNT):    # Для всех классов по порядку номеров (их меток)
    class_name = CLASS_LIST[class_label]  # Выборка имени класса из списка имен
    class_path = IMAGE_PATH + class_name  # Формирование полного пути к папке с изображениями класса
    class_files = os.listdir(class_path)  # Получение списка имен файлов с изображениями текущего класса
    print(f'Размер класса {class_name} составляет {len(class_files)} машин')

    # Добавление к общему списку всех файлов класса с добавлением родительского пути
    data_files += [f'{class_path}/{file_name}' for file_name in class_files]

    # Добавление к общему списку меток текущего класса - их ровно столько, сколько файлов в классе
    data_labels += [class_label] * len(class_files)

print('Общий размер базы для обучения:', len(data_labels))

import numpy as np
plt.style.use('ggplot')

count_labels = np.array(data_labels)
count = np.bincount(count_labels)

plt.bar(range(3), count, color=['#990099', '#006666', '#003399'])
plt.xlabel(f'Классы:{count}', c='#9900ff')
plt.ylabel('Количество', c='#9900ff')
plt.xticks([0, 1, 2])
plt.title('График количества элементов по классам', c='#996600')
plt.show()

count = np.bincount(count_labels)

"""Теперь в списках находятся пути к файлам и соответствующие им номера классов:

"""

print('Пути к файлам: ', data_files[1085:1090])
print('Их метки классов:', data_labels[1085:1090])

"""## Формирование набора данных из имеющейся базы

"""

# Задание единых размеров изображений

IMG_WIDTH = 128                           # Ширина изображения
IMG_HEIGHT = 64                           # Высота изображения

data_files[0]

import numpy as np                        # Библиотека работы с массивами

data_images = []                          # Пустой список для данных изображений

for file_name in data_files:
    # Открытие и смена размера изображения
    img = Image.open(file_name).resize((IMG_WIDTH, IMG_HEIGHT))
    img_np = np.array(img)                # Перевод в numpy-массив
    data_images.append(img_np)            # Добавление изображения в виде numpy-массива к общему списку

x_data = np.array(data_images)            # Перевод общего списка изображений в numpy-массив
y_data = np.array(data_labels)            # Перевод общего списка меток класса в numpy-массив

print(f'В массив собрано {len(data_images)} фотографий следующей формы: {img_np.shape}')
print(f'Общий массив данных изображений следующей формы: {x_data.shape}')
print(f'Общий массив меток классов следующей формы: {y_data.shape}')

x_data[0]

# Нормированние массива изображений
x_data = x_data / 255.

"""# Решение"""

# Ваше решение

import torch
from torch import nn
from torch.utils.data import DataLoader, TensorDataset, random_split
from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay

# подготовка данных
x_tensor = torch.tensor(x_data).permute(0, 3, 1, 2).float()
y_tensor = torch.tensor(y_data).long()
dataset = TensorDataset(x_tensor, y_tensor)

train_size = int(len(dataset) * 0.8)
val_size = int(len(dataset) * 0.1)
test_size = len(dataset) - train_size - val_size
train_ds, val_ds, test_ds = random_split(dataset, [train_size, val_size, test_size])

train_loader = DataLoader(train_ds, batch_size=32, shuffle=True)
val_loader = DataLoader(val_ds, batch_size=32)
test_loader = DataLoader(test_ds, batch_size=32)

# модель
class ConvNet(nn.Module):
    def __init__(self):
        super().__init__()
        self.features = nn.Sequential(
            nn.Conv2d(3, 16, 3, padding=1), nn.ReLU(), nn.MaxPool2d(2),
            nn.Conv2d(16, 32, 3, padding=1), nn.ReLU(), nn.MaxPool2d(2)
        )
        self.classifier = nn.Sequential(
            nn.Flatten(),
            nn.Linear(32 * (IMG_HEIGHT // 4) * (IMG_WIDTH // 4), 128),
            nn.ReLU(),
            nn.Dropout(0.3),
            nn.Linear(128, CLASS_COUNT)
        )

    def forward(self, x):
        x = self.features(x)
        return self.classifier(x)

model = ConvNet()
criterion = nn.CrossEntropyLoss()
optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)

epochs = 10
train_loss, val_loss = [], []
train_acc, val_acc = [], []

for epoch in range(epochs):
    # train
    model.train()
    epoch_loss, correct = 0.0, 0
    for xb, yb in train_loader:
        optimizer.zero_grad()
        out = model(xb)
        loss = criterion(out, yb)
        loss.backward()
        optimizer.step()
        epoch_loss += loss.item() * xb.size(0)
        correct += (out.argmax(1) == yb).sum().item()
    train_loss.append(epoch_loss / len(train_ds))
    train_acc.append(correct / len(train_ds))

    # validation
    model.eval()
    epoch_loss, correct = 0.0, 0
    with torch.no_grad():
        for xb, yb in val_loader:
            out = model(xb)
            loss = criterion(out, yb)
            epoch_loss += loss.item() * xb.size(0)
            correct += (out.argmax(1) == yb).sum().item()
    val_loss.append(epoch_loss / len(val_ds))
    val_acc.append(correct / len(val_ds))
    print(f"Epoch {epoch + 1}: train_loss={train_loss[-1]:.4f}, val_loss={val_loss[-1]:.4f}")

# визуализация loss/accuracy
plt.figure()
plt.plot(train_loss, label="train_loss")
plt.plot(val_loss, label="val_loss")
plt.xlabel("epoch")
plt.ylabel("loss")
plt.legend()
plt.show()

plt.figure()
plt.plot(train_acc, label="train_acc")
plt.plot(val_acc, label="val_acc")
plt.xlabel("epoch")
plt.ylabel("accuracy")
plt.legend()
plt.show()

# ConfusionMatrixDisplay
model.eval()
y_true, y_pred = [], []
with torch.no_grad():
    for xb, yb in test_loader:
        preds = model(xb).argmax(1)
        y_pred.extend(preds.tolist())
        y_true.extend(yb.tolist())

cm = confusion_matrix(y_true, y_pred)
ConfusionMatrixDisplay(cm, display_labels=CLASS_LIST).plot(xticks_rotation="vertical")
plt.show()

# инференс на случайном изображении теста
idx = random.randrange(len(test_ds))
image, label = test_ds[idx]
model.eval()
with torch.no_grad():
    pred = model(image.unsqueeze(0)).argmax(1).item()

print(f"Predicted class: {CLASS_LIST[pred]}")
plt.imshow(image.permute(1, 2, 0))
plt.title(f"Predicted: {CLASS_LIST[pred]}")
plt.axis("off")
plt.show()
